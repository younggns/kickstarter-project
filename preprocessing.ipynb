{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ks-projects-201801.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 4 rows with no 'name' field\n"
     ]
    }
   ],
   "source": [
    "# If 'name' field is empty, drop the row\n",
    "index_to_remove = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['name'] != row['name']:\n",
    "        index_to_remove.append(index)\n",
    "\n",
    "df = df.drop(index_to_remove)\n",
    "print(\"Removed %d rows with no 'name' field\" %len(index_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rows with 'failed' and 'successful', and encode these two values (failed: 0, successful: 1)\n",
    "drop_states = ['live', 'canceled', 'suspended', 'undefined']\n",
    "df.drop(df[df.state.isin(drop_states)].index, inplace=True)\n",
    "\n",
    "results = []\n",
    "for state in df['state']:\n",
    "    if state == 'failed':\n",
    "        results.append(0)\n",
    "    else:\n",
    "        results.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "launched, duration = [], []\n",
    "for start, end in zip(df['launched'], df['deadline']):\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d')\n",
    "    days = (end_date.date() - start_date.date()).days\n",
    "    duration.append(days)\n",
    "    launched.append(int(round(start_date.timestamp())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some unrelated columns\n",
    "drop_cols = ['ID', 'deadline', 'goal', 'launched', 'pledged', 'state', 'usd pledged', 'usd_pledged_real']\n",
    "df.drop(axis=1, inplace=True, labels=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = duration\n",
    "df['results'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_category_success = df.groupby('main_category')['results'].mean()\n",
    "df.main_category = df.main_category.apply(func=lambda x: main_category_success.at[x])\n",
    "\n",
    "category_success = df.groupby('category')['results'].mean()\n",
    "df.category = df.category.apply(func=lambda x: category_success.at[x])\n",
    "\n",
    "currency_success = df.groupby('currency')['results'].mean()\n",
    "df.currency = df.currency.apply(func=lambda x: currency_success.at[x])\n",
    "\n",
    "country_success = df.groupby('country')['results'].mean()\n",
    "df.country = df.country.apply(func=lambda x: country_success.at[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some shallow linguistic features as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<preproc>\n",
    "- remove (Canceled), (Suspended)\n",
    "- remove quotation in the beginning and at the end\n",
    "- remove quotation elongation\n",
    "\n",
    "- Num of words\n",
    "- Num of named entities\n",
    "- Use of quotation\n",
    "- Use of elongation\n",
    "- Num of all capital words\n",
    "- Num of special characters (:, !, ?, #, etc.)\n",
    "\n",
    "- Glove word embedding + average\n",
    "- TF-IDF embedding?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Air Bonsai | Create your \"little star\"'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '\"Air Bonsai | Create your \"\"little star\"\"\"'\n",
    "ss = stringProc(s)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringProc(s):\n",
    "    s = s.strip()\n",
    "    s = s.replace(\"(Canceled)\",'').replace(\"(Suspended)\",'')\n",
    "    while True:\n",
    "        if s.startswith('\"') and s.endswith('\"'):\n",
    "            s = s[1:-1]\n",
    "        else:\n",
    "            break\n",
    "    s = s.replace('\"\"\"\"','\"').replace('\"\"\"','\"').replace('\"\"','\"')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def stringEncoding(s):\n",
    "    doc = nlp(s)\n",
    "    \n",
    "    numWords = len(doc)\n",
    "    numEntities = len(doc.ents)\n",
    "    \n",
    "    numAllCap, numSpecialChar = 0, 0\n",
    "    for tok in doc:\n",
    "        if tok.text == tok.text.upper():\n",
    "            numAllCap += 1\n",
    "        if tok.text in \"`~!@#$%^&*()-_=+{}[]:;<>?/'\\|,.\":\n",
    "            numSpecialChar += 1\n",
    "            \n",
    "    \n",
    "    useOfQuot = 1 if '\"' in doc.vocab else 0\n",
    "    \n",
    "    return numWords, numEntities, numAllCap, numSpecialChar, useOfQuot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for title in df['name']:    \n",
    "    names.append(stringProc(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331672/331672 [50:19<00:00, 109.84it/s] \n"
     ]
    }
   ],
   "source": [
    "numWords, numEntities, numAllCap, numSpecialChar, useOfQuot = [], [], [], [], []\n",
    "for elem in tqdm(names):\n",
    "    nw, ne, na, ns, uq = stringEncoding(elem)\n",
    "    numWords.append(nw)\n",
    "    numEntities.append(ne)\n",
    "    numAllCap.append(na)\n",
    "    numSpecialChar.append(ns)\n",
    "    useOfQuot.append(uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_clamp(results, threshold):\n",
    "    output = []\n",
    "    for elem in results:\n",
    "        if elem >= threshold:\n",
    "            output.append(threshold)\n",
    "        else:\n",
    "            output.append(elem)\n",
    "    return output\n",
    "            \n",
    "numWords_trunc = metadata_clamp(numWords, 25)\n",
    "numAllCap_trunc = metadata_clamp(numAllCap, 23)\n",
    "numSpecialChar_trunc = metadata_clamp(numSpecialChar, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = numWords_trunc\n",
    "df['num_entities'] = numEntities\n",
    "df['num_allcaps'] = numAllCap_trunc\n",
    "df['num_special'] = numSpecialChar_trunc\n",
    "df['use_quot'] = useOfQuot\n",
    "df['name'] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = ['name', 'category', 'main_category', 'currency', 'country', 'duration', 'backers', 'usd_goal_real', 'num_words', 'num_entities', 'num_allcaps', 'num_special', 'use_quot', 'results']\n",
    "df = df.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.sample(random_state=47, frac=0.2)\n",
    "df_train = df.drop(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Origami Star Flower',\n",
       " 'Finish The Tales Of Extraordinary Beings Series',\n",
       " 'Petitjean Paris | A silk ready-to-wear line',\n",
       " 'Newsome Awards',\n",
       " 'Make \"Ever With You\" possible to be released this year!!!',\n",
       " 'Sleeping Bag Sheet',\n",
       " 'Whale Stapler',\n",
       " 'Resurrecting Rodney',\n",
       " 'National Park Postcard Adventure',\n",
       " 'ALEX LONDON NYFW 2012 SPRING SUMMER NEEDS YOUR HELP!',\n",
       " 'The Holy Land Project',\n",
       " 'NINJA HIGH SCHOOL Expandable Card Game',\n",
       " 'Steppin with style tv show',\n",
       " '360° India',\n",
       " \"Meet SYRE, The World's First Bluetooth iPod Nano Watch Case\",\n",
       " '\"Those Behind\" a Horror Novel By Tim Scalita',\n",
       " 'Emmerst - Self Titled Deathcore / Nu Metal EP',\n",
       " 'The Barefoot Movement \"Figures of the Year\"',\n",
       " \"PEANUTBUTTER & JELLY PLAYERS Children's Theater\",\n",
       " 'Custom Art Card Sleeves, for Magic the Gathering, etc.',\n",
       " 'Copse GP Greenpower Team',\n",
       " 'Legends of the Boo-Monster',\n",
       " 'EXP puppet troupe is currently filming \"King Daddy Sunshine\"',\n",
       " 'I want to build a Trebuchet and have fun.',\n",
       " 'Ovulation (a drama / horror film)',\n",
       " 'Virtual Choir 4: Bliss',\n",
       " 'Baobab Apparel',\n",
       " 'Curtis Pride - I Felt The Cheers',\n",
       " \"Help Bring 'Mud' to the Fringe\",\n",
       " 'The Fish Mall',\n",
       " 'The Listeners - A film about suicide prevention hotlines',\n",
       " \"Jacob's Ladder Tree: A Christmas Ornament\",\n",
       " 'Isaiah Rodriguez Campaign',\n",
       " 'The Tsunami of Love',\n",
       " 'Sexy Secrets',\n",
       " 'Defend Evolution With Clear Friendly Instruction',\n",
       " 'Hacking into Heaven: Mushrooms and the Bible',\n",
       " 'Photos of China',\n",
       " 'LunarMessaging.net',\n",
       " 'MC Lars - \"Greatest Hits\" (ON VINYL) & \"Edgar Allan Poe EP\"',\n",
       " 'Stay in touch with your Southern Roots',\n",
       " \"Numbers... A Gangsta's Child\",\n",
       " \"Mother's Day Father's Day Custom Wood Photo Piece!\",\n",
       " 'I See Ed Steeple.',\n",
       " \"Crazy fun clothing kids love that makes them safe! I'm ready\",\n",
       " '\"Loc\" - Can You Escape?',\n",
       " 'make a \"beautiful mistake\" with Art as Action',\n",
       " 'Tabletop Adventures With TableTop Genesis',\n",
       " 'Tafahum Album - Fusion of Classical Arabic & Western Music.',\n",
       " \"Don't You Deserve a Choice?\",\n",
       " 'Kingdoms of Erden: Fantasy Playing Cards',\n",
       " 'The Event with No Name: Plymouth International Tabletop Day',\n",
       " 'The Push Chronicles & Three Seconds to Legend: Take 2!',\n",
       " 'The Masada Story Project',\n",
       " '~ TWO RIVERS ~',\n",
       " 'Mission to bring music lovers a festival to remember',\n",
       " 'I am going to make Barbecued Salmon wrapped in Bacon',\n",
       " 'FIXING A HOLE (novel)',\n",
       " 'SEA ROOM, a new play by Jordan Gullikson',\n",
       " 'Life Size Pokemon: Blitzle, Deerling, and ???',\n",
       " 'The Rogers Park Free Little Library',\n",
       " 'MY FRIEND PETER, the Feature Film!',\n",
       " 'I-OpenR - Effortless Automation for Chicken Coop Doors',\n",
       " 'Lionhearted 360 VR',\n",
       " 'Teenage Rehab \"More Than A Job\" Vinyl LP Re-Issue.',\n",
       " 'The Wall',\n",
       " 'Make Wonderland a Reality',\n",
       " 'KITS DE INICIO EN EL TAROT',\n",
       " 'Full Circle',\n",
       " '\"SHOW ME THE HOFAX\" NEW HOFAX APP #hofax, #catfax, #cockfax,',\n",
       " 'doosh/off: a party game for people with opinions',\n",
       " 'Journey to Success: Summer School 2014 Documentary',\n",
       " 'Marriage License Reality Board game',\n",
       " 'ROGER',\n",
       " 'The Undergraduate Scholarship Quarterly',\n",
       " 'Springtime in Paris - a premiere ballet',\n",
       " 'The Reverend Screaming Fingers Big Band in SF & NYC!',\n",
       " '\"Boo:ooM\" - Album & Animated Music Video Project',\n",
       " 'cozy joey by Mulier™',\n",
       " 'Greg Chambers Saxophone CD',\n",
       " 'My Painting Project',\n",
       " '22 Sydney Jewelry: Stylish silicone bracelet jewelry.',\n",
       " 'Lazarus',\n",
       " 'Wild Skies: Europa Tempest',\n",
       " 'Good People by David Lindsay-Abaire at Waterfront Playhouse',\n",
       " 'Development of a Political thriller novel: Veiled Power',\n",
       " 'Phoenix Project: Who Shall Rise?',\n",
       " 'Uwroteit.com',\n",
       " 'Meadows Way',\n",
       " 'Femme and Flora - An Adult Coloring Book',\n",
       " 'Help National Lines record their first EP!',\n",
       " '14 dice sets compatible w/ Dungeon Crawl Classics +D9 D11',\n",
       " 'My First Language Lesson by Chatterfun Media',\n",
       " 'The Dissertation Warrior',\n",
       " 'Taken 4 Granite CD',\n",
       " 'We Lift Him Up',\n",
       " 'The Herd',\n",
       " 'REVIVAL',\n",
       " 'TAKE A KID TO IT',\n",
       " 'Hazard / Are You Lonesome Tonight']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['name'].tolist()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('testSet.csv', sep=',', index=False)\n",
    "df_train.to_csv('trainingSet.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attributes to use: \n",
    "    - name\n",
    "    - category\n",
    "    - main_category\n",
    "    - backers\n",
    "    - duration (deadline - launched)\n",
    "    - country\n",
    "    - usd_goal_real\n",
    "\n",
    "Objective:\n",
    "    - regress usd_pledged_real OR percentage (usd_pledged_real / usd_goal_real * 100)\n",
    "    - predict state (successful or not)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess category, main_category, country\n",
    "def attr_encoding(df, attr_name):\n",
    "    encoded = []\n",
    "    unique_values = sorted(list(set(df[attr_name])))\n",
    "    for elem in df[attr_name]:\n",
    "        encoded.append(unique_values.index(elem))\n",
    "    return encoded\n",
    "\n",
    "category = attr_encoding(df_copy, 'category')\n",
    "main_category = attr_encoding(df_copy, 'main_category')\n",
    "country = attr_encoding(df_copy, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = sorted(Counter(df_copy['country']).items(), key=lambda x:x[1], reverse=True)\n",
    "x = [key for key, val in cs]\n",
    "label = [val for key, val in cs]\n",
    "plt.bar(x, label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "num_backers: skewed distribution -> range of log scale count\n",
    "0: 55609\n",
    "1, 2: 58065\n",
    "3 ~ 7: 52998\n",
    "8 ~ 20: 53692\n",
    "21 ~ 47: 53213\n",
    "48 ~ 116: 52449\n",
    "117 ~ : 52635\n",
    "\"\"\"\n",
    "def encodeBackers(num_backers):\n",
    "    encode_dict = {0: [0], 1: [1, 2], 2: range(3, 8), 3: range(8, 21), 4: range(21, 48), 5: range(48, 117)}\n",
    "    encoded_backers = -1\n",
    "    for key, val in encode_dict.items():\n",
    "        if num_backers in val:\n",
    "            encoded_backers = key\n",
    "    if encoded_backers == -1:\n",
    "        encoded_backers = 6\n",
    "    return encoded_backers\n",
    "\n",
    "backers = []\n",
    "for elem in df_copy['backers']:\n",
    "    backers.append(encodeBackers(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "duration = []\n",
    "duration_raw = []\n",
    "for start, end in zip(df_copy['launched'], df_copy['deadline']):\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d %H:%M:%S').date()\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d').date()\n",
    "    days = 0 if (end_date - start_date).days <= 30 else 1\n",
    "    duration.append(days)\n",
    "    duration_raw.append((end_date - start_date).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df_copy['usd_goal_real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnGoalEncodeDict(df):\n",
    "    sorted_ctr = sorted(Counter(df['usd_goal_real'].values.tolist()).items(), key=lambda x:x[0])\n",
    "    counter, range_threshold = 0, []\n",
    "    for key, val in sorted_ctr:\n",
    "        counter += val\n",
    "        if counter >= 5000 and key == int(key):\n",
    "            # print(int(key), counter)\n",
    "            range_threshold.append(int(key))\n",
    "            counter = 0\n",
    "            \n",
    "    encode_dict = {key: None for key in range(len(range_threshold))}\n",
    "    range_a, range_b = 0, 0\n",
    "    eps = 1e-6\n",
    "    for key in encode_dict.keys():\n",
    "        range_b = range_threshold[key]\n",
    "        encode_dict[key] = (range_a, range_b+eps)\n",
    "        range_a = range_b+eps\n",
    "        \n",
    "    return encode_dict\n",
    "\n",
    "def encodeGoal(goal_amount, encode_dict):\n",
    "    encoded_goal = -1\n",
    "    for key, val in encode_dict.items():\n",
    "        if goal_amount >= val[0] and goal_amount < val[1]:\n",
    "            encoded_goal = key\n",
    "    if encoded_goal == -1:\n",
    "        encoded_goal = len(encode_dict.keys())\n",
    "\n",
    "    return encoded_goal\n",
    "\n",
    "encode_dict = returnGoalEncodeDict(df_copy)\n",
    "\n",
    "goals, pledged = [], []\n",
    "for elem in df_copy['usd_goal_real']:\n",
    "    goals.append(encodeGoal(elem, encode_dict))\n",
    "for elem in df_copy['usd_pledged_real']:\n",
    "    pledged.append(encodeGoal(elem, encode_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for pled, goal in zip(df_copy['usd_pledged_real'], df_copy['usd_goal_real']):\n",
    "    if pled >= goal:\n",
    "        states.append(1)\n",
    "    else:\n",
    "        states.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = sorted(Counter(percentage).items(), key=lambda x:x[0], reverse=False)\n",
    "keydict = {0: '0%', 1: '1~10%', 2: '11~99%', 3: '100~120%', 4: '121%~'}\n",
    "x = [keydict[key] for key, val in cs]\n",
    "label = [val for key, val in cs]\n",
    "plt.bar(x, label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodePercentage(p):\n",
    "    encode_dict = {0: [0], 1: range(1, 11), 2: range(11, 100), 3: range(100, 121)}\n",
    "    encoded_p = -1\n",
    "    for key, val in encode_dict.items():\n",
    "        if p in val:\n",
    "            encoded_p = key\n",
    "    if encoded_p == -1:\n",
    "        encoded_p = 4\n",
    "    return encoded_p\n",
    "\n",
    "percentage = []\n",
    "percentage_raw = []\n",
    "for pled, goal in zip(df_copy['usd_pledged_real'], df_copy['usd_goal_real']):\n",
    "    p = int(pled / goal * 100)\n",
    "    percentage_raw.append(p)\n",
    "    percentage.append(encodePercentage(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(duration) == len(category) == len(main_category) == len(country) == len(backers) == len(goals) == len(pledged) == len(states) == len(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords, numEntities, numAllCap, numSpecialChar, useOfQuot, useOfElong = [], [], [], [], [], []\n",
    "for elem in names:\n",
    "    nw, ne, na, ns, uq, ue, tok = stringEncoding(elem)\n",
    "    numWords.append(nw)\n",
    "    numEntities.append(ne)\n",
    "    numAllCap.append(na)\n",
    "    numSpecialChar.append(ns)\n",
    "    useOfQuot.append(uq)\n",
    "    useOfElong.append(ue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"iCare FHD: World's First Urgent Home Care Camera\"\n",
    "doc2 = nlp(c)\n",
    "for tok in doc2:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"'s\" in \"`~!@#$%^&*()-_=+{}[]:;<>?/'\\|,.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'LEDIONIX #ONE - Linear T8 LED-Light - \"One for all!!!\"'\n",
    "b = '1yrBeer - Discovering Craft Beer Culture in Colorado,Documentary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Linear\".isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(a)\n",
    "print(len(doc))\n",
    "for tok in doc:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(a)\n",
    "tok_len = len(doc)\n",
    "remove_elong = []\n",
    "for i, tok in enumerate(doc):\n",
    "    if i == tok_len-1:\n",
    "        print(\"here\", tok)\n",
    "        remove_elong.append(tok)\n",
    "    else:\n",
    "        print(tok, doc[i+1])\n",
    "        if tok.text == doc[i+1].text:\n",
    "            continue\n",
    "        else:\n",
    "            remove_elong.append(tok)\n",
    "print(remove_elong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = []\n",
    "for elem in names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['state'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.values:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for elem in df[df['state']=='canceled'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"canceled pledged count: %d out of %d\" %(cnt, len(df[df['state']=='canceled'])))\n",
    "\n",
    "cnt = 0\n",
    "for elem in df[df['state']=='failed'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"failed pledged count: %d out of %d\" %(cnt, len(df[df['state']=='failed'])))\n",
    "\n",
    "cnt = 0\n",
    "for elem in df[df['state']=='live'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"live pledged count: %d out of %d\" %(cnt, len(df[df['state']=='live'])))\n",
    "\n",
    "cnt = 0\n",
    "for elem in df[df['state']=='successful'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"successful pledged count: %d out of %d\" %(cnt, len(df[df['state']=='successful'])))\n",
    "\n",
    "cnt = 0\n",
    "for elem in df[df['state']=='suspended'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"suspended pledged count: %d out of %d\" %(cnt, len(df[df['state']=='suspended'])))\n",
    "\n",
    "cnt = 0\n",
    "for elem in df[df['state']=='undefined'].values:\n",
    "    if elem[-2] >= elem[-1]:\n",
    "        cnt += 1\n",
    "print(\"undefined pledged count: %d out of %d\" %(cnt, len(df[df['state']=='undefined'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
    "def removeElongToken(doc):\n",
    "    idx = []\n",
    "    for i, tok in enumerate(doc):\n",
    "        if i != tok_len-1 and tok.text == doc[i+1].text:\n",
    "            idx.append(i)\n",
    "    np_array = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])\n",
    "    doc2 = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in idx])\n",
    "    doc2.from_array([LOWER, POS, ENT_TYPE, IS_ALPHA], np_array)\n",
    "    return doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "regex = re.compile(r'(.)\\1{2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
